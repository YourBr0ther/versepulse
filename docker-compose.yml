services:
  versepulse:
    build: .
    container_name: versepulse
    restart: unless-stopped
    environment:
      - PUSHBULLET_API_KEY=${PUSHBULLET_API_KEY}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-mistral}
      - CHECK_INTERVAL=${CHECK_INTERVAL:-10}
      - FORUM_URL=${FORUM_URL:-https://robertsspaceindustries.com/spectrum/community/SC/forum/190048}
    volumes:
      - ./data:/app/data
    # Use host network to access external Ollama server
    network_mode: host

  # Uncomment below to run Ollama locally in Docker
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: versepulse-ollama
  #   restart: unless-stopped
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   # Uncomment below to enable GPU support (NVIDIA)
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]

# volumes:
#   ollama_data:
